protocolVersion: 2
name: hived-distributed-tf
type: job
parameters:
  model: resnet20
  batchsize: 32
prerequisites:
  - protocolVersion: 2
    name: tf_example
    type: dockerimage
    version: 1.0-r1.4
    uri: openpai/pai.example.tensorflow
  - protocolVersion: 2
    name: tensorflow_cifar10_model
    type: output
    uri: 'hdfs://10.151.40.234:9000/core/cifar10_model'
  - protocolVersion: 2
    name: tensorflow_cnnbenchmarks
    type: script
    version: 84820935288cab696c9c2ac409cbd46a1f24723d
    uri: 'https://github.com/MaggieQi/benchmarks'
  - protocolVersion: 2
    name: cifar10
    type: data
    uri:
      - 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'
taskRoles:
  worker:
    instances: 1
    completion:
      minSucceededInstances: 1
    dockerImage: tf_example
    data: cifar10
    output: tensorflow_cifar10_model
    script: tensorflow_cnnbenchmarks
    resourcePerInstance:
      cpu: 2
      memoryMB: 16384
      gpu: 4
    commands:
      - cd script_<% $script.name %>/scripts/tf_cnn_benchmarks
      - >
        python tf_cnn_benchmarks.py --job_name=worker
        --local_parameter_device=gpu --variable_update=parameter_server
        --ps_hosts=$PAI_TASK_ROLE_ps_HOST_LIST
        --worker_hosts=$PAI_TASK_ROLE_worker_HOST_LIST
        --task_index=$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX --data_name=<%
        $data.name %> --data_dir=/data_<% $data.name %> --train_dir=/output_<%
        $output.name %> --model=<% $parameters.model %> --batch_size=<%
        $parameters.batchsize %>
  ps:
    instances: 1
    completion:
      minSucceededInstances: 1
    dockerImage: tf_example
    data: cifar10
    output: tensorflow_cifar10_model
    script: tensorflow_cnnbenchmarks
    resourcePerInstance:
      cpu: 2
      memoryMB: 8192
      gpu: 1
    commands:
      - cd script_<% $script.name %>/scripts/tf_cnn_benchmarks
      - >
        python tf_cnn_benchmarks.py --job_name=ps --local_parameter_device=gpu
        --variable_update=parameter_server
        --ps_hosts=$PAI_TASK_ROLE_ps_HOST_LIST
        --worker_hosts=$PAI_TASK_ROLE_worker_HOST_LIST
        --task_index=$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX
        --data_dir=/data_<% $data.name %> --data_name=<% $data.name %>
        --train_dir=/output_<% $output.name %> --model=<% $parameters.model %>
        --batch_size=<% $parameters.batchsize %>
deployments:
  - name: tf_example
    taskRoles:
      worker:
        preCommands:
          - rm /usr/local/cuda/lib64/stubs/libcuda.so.1
          - >-
            wget -qO- <% $data.uri[0] %> | tar xvz && mv cifar-10-batches-py
            /data_<% $data.name %>
          - >
            git clone <% $script.uri %> script_<% $script.name %> && cd
            script_<% $script.name %> && git checkout <% $script.version %> &&
            cd ..
        postCommands:
          - sleep 10
      ps:
        preCommands:
          - rm /usr/local/cuda/lib64/stubs/libcuda.so.1
          - >-
            wget -qO- <% $data.uri[0] %> | tar xvz && mv cifar-10-batches-py
            /data_<% $data.name %>
          - >
            git clone <% $script.uri %> script_<% $script.name %> && cd
            script_<% $script.name %> && git checkout <% $script.version %> &&
            cd ..
        postCommands:
          - echo "Uploading data ..."
defaults:
  deployment: tf_example
extras:
  submitFrom: submit-job-v2
