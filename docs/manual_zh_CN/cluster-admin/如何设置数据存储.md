# 如何设置数据存储

本文档介绍了如何使用Kubernetes持久卷（PV）作为PAI上的存储。 要设置现有存储（nfs，samba，Azure blob等），您需要：

  1. 在Kubernetes上创建PV和PVC作为PAI存储。
  2. 确认工作程序节点具有正确的软件包以安装PVC。例如，`NFS`PVC需要软件包`nfs-common`才能在Ubuntu上运行。
  3. 将PVC分配给特定的用户组。

正确设置存储后，用户可以将这些PV/PVC装入其任务中。 PVC的名称用于PAI上。

## 在Kubernetes中创建PV和PVC 

创建PV/PVC的方法很多，如果您还不熟悉，可以参考[Kubernetes 文档](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) 。 以下是一些常用的PV/PVC示例。

### NFS

```yaml
# NFS Persistent Volume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-storage-pv
  labels:
    name: nfs-storage
spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
    - nfsvers=4.1
  nfs:
    path: /data
    server: 10.0.0.1
---
# NFS Persistent Volume Claim
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-storage
# labels:
#   share: "false"      # to mount sub path on PAI
spec:
  accessModes:
    - ReadWriteMany
  volumeMode: Filesystem
  resources:
    requests:
      storage: 10Gi    # no more than PV capacity
  selector:
    matchLabels:
      name: nfs-storage # corresponding to PV label
```

将以上文件另存为`nfs-storage.yaml`，然后运行`kubectl apply -f nfs-storage.yaml`，为nfs服务器`nfs://10.0.0.1:/data`创建一个名为`nfs-storage-pv` 的PV和一个名为`nfs-storage`的PVC。PVC将通过标签选择器使用标签`name: nfs-storage`绑定到特定的PV。

用户可以使用PVC名称`nfs-storage`作为存储名称，以在其任务中挂载该nfs存储。

例如，如果要将上述nfs配置为个人存储，以便每个用户只能访问自己在PAI上的目录，例如Linux主目录，那么Alice只能安装`/data/Alice` ，而Bob只能安装`/data/Bob`，您可以在PVC上添加一个`share: "false"`标签。 在这种情况下，当安装到任务容器时，PAI将使用`${PAI_USER_NAME}` 作为子路径。

### Samba

请参考 [本文档](https://github.com/Azure/kubernetes-volume-drivers/blob/master/flexvolume/smb/README.md) 来安装`cifs/smb FlexVolume`的驱动以及为`Samba`创建`PV/PVC`。

### Azure Blob

请参考 [本文档](https://github.com/Azure/kubernetes-volume-drivers/blob/master/flexvolume/blobfuse/README.md) 来安装`blobfuse FlexVolume`的驱动以及为`Azure Blob`创建`PV/PVC`。

#### 提示

如果您无法将`blobfuse PVC`安
装到容器中，并且OpenPAI中的相应任务处于`等待`状态，请仔细检查以下要求：

**要求1.** 每个工作节点都应安装`blobfuse`。尝试以下命令以确保：

```bash
# change 16.04 to a different release if your system is not Ubuntu 16.04
wget https://packages.microsoft.com/config/ubuntu/16.04/packages-microsoft-prod.deb
sudo dpkg -i packages-microsoft-prod.deb
sudo apt-get update
sudo apt-get install --assume-yes blobfuse fuse
```

**要求2.** `blobfuse` FlexVolume驱动程序已安装：

```sh
curl -s https://raw.githubusercontent.com/Azure/kubernetes-volume-drivers/master/flexvolume/blobfuse/deployment/blobfuse-flexvol-installer-1.9.yaml \
  | sed "s#path: /etc/kubernetes/volumeplugins/#path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/#g" \
  | kubectl apply -f -
```

> NOTE: 在同一节点上多次安装同一PV存在一个已知问题[#4637](https://github.com/microsoft/pai/issues/4637) ，可以选择以下两种处理方法:
>   * 用 [blobfuse flexvolume补丁安装程序](https://github.com/microsoft/pai/issues/4637#issuecomment-647434815) 来代替。
>   * 用 [earlier version 1.1.1](https://github.com/Azure/kubernetes-volume-drivers/issues/66#issuecomment-649188681) 来代替。

### Azure File

首先创建一个Kubernetes机密，以访问Azure文件共享。

```sh
kubectl create secret generic azure-secret --from-literal=azurestorageaccountname=$AKS_PERS_STORAGE_ACCOUNT_NAME --from-literal=azurestorageaccountkey=$STORAGE_KEY
```

然后Azure文件创建PV/PVC。

```yaml
# Azure File Persistent Volume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: azure-file-storage-pv
  labels:
    name: azure-file-storage
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteMany
  storageClassName: azurefile
  azureFile:
    secretName: azure-secret
    shareName: aksshare
    readOnly: false
  mountOptions:
    - dir_mode=0777
    - file_mode=0777
    - uid=1000
    - gid=1000
    - mfsymlinks
    - nobrl
---
# Azure File Persistent Volume Claim
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: azure-file-storage
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: azurefile
  resources:
    requests:
      storage: 5Gi
  selector:
    matchLabels:
      name: azure-file-storage
```

可以在[本文档](https://docs.microsoft.com/en-us/azure/aks/azure-files-volume) 中找到有关Azure文件卷的更多详细信息。.

### 只读存储

如果未指定，则用户可以读写OpenPAI中的存储。 如果您希望存储为只读，请将相应的PV的属性`PersistentVolume.Spec.<PersistentVolumeSource>.ReadOnly`ReadOnly设置为`true`。

例如，您可以通过在其定义中指定`spec.nfs.readOnly`字段来设置只读NFS PV：

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-storage-pv
  labels:
    name: nfs-storage
spec:
  ......
  nfs:
    readOnly: true
    .......
```

这是AzureBlob的另一个示例：

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: azure-file-storage-pv
  labels:
    name: azure-file-storage
spec:
  ......
  flexVolume:
    readOnly: true
    .......
```

请注意，`PersistentVolume.Spec.AccessModes` 和`PersistentVolumeClaim.Spec.AccessModes`不会影响存储在PAI中是否可写。 它们仅在PV和PVC之间的绑定时间内生效。

## <div id="confirm-environment-on-worker-nodes">确认Worker结点上的环境</div>

[Kubernetes文件中的声明](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistent-volumes) 提到：辅助程序可能需要消耗一定类型PersistentVolume的。 例如，如果要使用`NFS` PV，则所有工作节点都应安装`nfs-common`。 您可以在每个工作节点上使用命令`apt install nfs-common`来确认它。

由于不同的PV有不同的要求，因此应根据PV的文档检查环境。

## <div id="assign-storage-to-pai-groups">将存储授权给用户组</div>

PVC名称在OpenPAI中用作存储名称。设置PV/PVC并检查环境后，需要将存储分配给用户。在OpenPAI中，PVC的名称用作存储名称，不同存储的访问由[用户组](./如何管理用户和用户组.md)管理。要将存储分配给用户，请使用RESTful API将存储分配给用户组。

在查询API之前，您应该获取API的访问令牌。 转到您的个人资料页面并复制以下内容之一：

<img src="./imgs/get-token.png" />

在OpenPAI中，存储绑定到组。 因此，您可以使用 [Group API](https://redocly.github.io/redoc/?url=https://raw.githubusercontent.com/microsoft/pai/master/src/rest-server/docs/swagger.yaml#tag/group) 将存储分配给组。然后[更新其扩展名](https://redocly.github.io/redoc/?url=https://raw.githubusercontent.com/microsoft/pai/master/src/rest-server/docs/swagger.yaml#operation/updateGroup) 。

例如，如果要将`nfs-storage` PVC分配给`default`组。 首先，获取`http(s)://<pai-master-ip>/rest-server/api/v2/groups/default`，它将返回：

```json
{
  "groupname": "default",
  "description": "group for default vc",
  "externalName": "",
  "extension": {
    "acls": {
      "storageConfigs": [],
      "admin": false,
      "virtualClusters": ["default"]
    }
  }
}
```

GET请求必须使用标头`Authorization：Bearer <token>`进行授权。 所有API调用均保持相同。 您可能会在返回正文中注意到`storageConfigs`。 实际上，它控制着哪一个存储组可以使用。 要在其中添加一个`nfs-storage`，请输入`http(s)://<pai-master-ip>/rest-server/api/v2/groups`。 请求正文为：

```json
{
  "data": {
    "groupname": "default",
    "extension": {
      "acls": {
        "storageConfigs": ["nfs-storage"],
        "admin": false,
        "virtualClusters": ["default"]
      }
    }
  },
  "patch": true
}
```

请勿在`extension`中省略任何字段，否则会意外更改`virtualClusters`设置。

## 示例: 使用Storage Manager创建NFS + SAMBA服务器

为了帮助您设置存储，OpenPAI提供了一个存储管理器，可以设置NFS + SAMBA服务器。 在集群中，可以在OpenPAI容器中访问NFS存储。 在集群之外，用户可以在类似Unix的系统上装载存储，或在Windows的文件资源管理器中访问它。

请首先阅读有关 [服务管理和paictl](./基础管理操作.md#pai-service-management-and-paictl) 的文档，然后启动开发盒容器。然后，在dev box容器中，通过以下方式提取配置：

```bash
./paictl config pull -o /cluster-configuration
```

要使用存储管理器，您首先应该将PAI系统中的一台机器确定为存储服务器。 机器`必须`是PAI工作者之一，而不是PAI管理员。 请打开`/cluster-configuration/layout.yaml`，选择一个工作计算机，然后在其中添加一个`pai-storage: "true"`字段。 这是编辑后的`layout.yaml`的示例：

```yaml
......

- hostname: worker1
  nodename: worker1
  hostip: 10.0.0.1
  machine-type: GENERIC-WORKER
  pai-worker: "true"
  pai-storage: "true"  # this line is newly added

......
```

在本教程中，我们假设您选择IP为`10.0.0.1`的计算机作为存储服务器。 然后，在`/cluster-configuration/services-configuration.yaml`中，找到存储管理器部分：

```yaml
# storage-manager:
#   localpath: /share
#   security-type: AUTO
#   workgroup: WORKGROUP
#   smbuser: smbuser
#   smbpwd: smbpwd
```

取消注释：

```yaml
storage-manager:
  localpath: /share
#  security-type: AUTO
#  workgroup: WORKGROUP
  smbuser: smbuser
  smbpwd: smbpwd
```

`localpath`确定存储服务器上NFS的根数据目录。 当您在Windows上的文件资源管理器中访问存储时，`smbuser`和`smbpwd`确定用户名和密码。

请遵循以下命令来启动存储管理器：

```bash
./paictl.py service stop -n cluster-configuration storage-manager
./paictl.py config push -p /cluster-configuration -m service
./paictl.py service start -n cluster-configuration storage-manager
```

如果存储管理器成功启动，您将在存储服务器上找到文件夹`/share/data`和`/share/users`。 在Ubuntu计算机上，可以使用以下命令测试NFS服务器是否正确设置：

```bash 
# replace 10.0.0.1 with your storage server IP
sudo apt update 
sudo apt install nfs-common
mkmdir -p /mnt/data
sudo mount -t nfs --options nfsvers=4.1 10.0.0.1:/data/ /mnt/data
```

为了使NFS存储在PAI中可用，我们应该为其创建PV和PVC。 因此，首先在dev box容器中创建以下`nfs-storage.yaml`文件：

```yaml
# replace 10.0.0.1 with your storage server IP
# NFS Persistent Volume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-storage-pv
  labels:
    name: nfs-storage
spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
    - nfsvers=4.1
  nfs:
    path: /data
    server: 10.0.0.1
---
# NFS Persistent Volume Claim
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-storage
# labels:
#   share: "false"      # to mount sub path on PAI
spec:
  accessModes:
    - ReadWriteMany
  volumeMode: Filesystem
  resources:
    requests:
      storage: 10Gi    # no more than PV capacity
  selector:
    matchLabels:
      name: nfs-storage # corresponding to PV label
```

使用`kubectl create -f nfs-storage.yaml`创建PV和PVC。

由于Kuberentes PV要求使用它的节点具有相应的驱动程序，所以我们应该使用apt install nfs-common在每个工作节点上安装nfs-common软件包。

最后，通过rest-server API [将存储分配给PAI组](#assign-storage-to-pai-groups) 。 然后，您可以将其安装到任务容器中。

如何上传数据到存储服务器？ 在Windows上，打开“文件资源管理器”，键入`\\ 10.0.0.1`（请将 `10.0.0.1`更改为存储服务器IP），然后按Enter。 文件资源管理器将要求您授权。 请使用`smbuser`和`smbpwd`作为用户名和密码登录。 在类似Unix的系统上，可以将NFS文件夹安装到文件系统上。 例如，在Ubuntu上，使用以下命令进行安装：

```bash 
# replace 10.0.0.1 with your storage server IP
sudo apt update 
sudo apt install nfs-common
mkmdir -p /mnt/data
sudo mount -t nfs --options nfsvers=4.1 10.0.0.1:/data/ /mnt/data
```

The above steps only set up a basic SAMBA server. So each user shares the same username and password to access it on Windows. If your cluster is in [AAD mode](./如何管理用户和用户组.md#users-and-groups-in-aad-mode), and you want to integrate the SAMBA server with the AAD system, please refer to the following configuration for storage manager:
上述步骤仅设置了基本的SAMBA服务器。 因此，每个用户共享相同的用户名和密码以在Windows上进行访问。 如果您的群集处于[AAD模式](./如何管理用户和用户组.md#users-and-groups-in-aad-mode)，并且您想要将SAMBA服务器与AAD系统集成，请参阅以下的Storage Manager的配置：

```yaml
storage-manager:
  workgroup: # workgroup
  security-type: ADS
  default_realm: # default realm
  krb5_realms: # realms
    XXX1: # relam name
      kdc: # kdc
      default_domain: # default domain
    XXX2: # relam name
      kdc: # kdc
      default_domain: # default domain
  domain_realm: # domain realm
    kdc: # kdc
    default_domain: # default domain
  domainuser: # domain user
  domainpwd: # password of domain user
  idmap: # idmap
  - "idmap config XXX1"
  - "idmap config XXX2"
  - "idmap config XXX3"
  - "idmap config XXX4"
```
