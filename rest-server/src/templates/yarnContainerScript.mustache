#!/bin/bash

# Copyright (c) Microsoft Corporation
# All rights reserved.
#
# MIT License
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
# to permit persons to whom the Software is furnished to do so, subject to the following conditions:
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
# BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


# Entrypoint script for yarn container.

exec 13>/tmp/pai_yarncontainer_$CONTAINER_ID.log
BASH_XTRACEFD=13

function exit_handler()
{
  printf "%s %s\n" \
    "[ERROR]" "EXIT signal received in yarn container, exiting ..."
  set +x
  exec 13>&-
  hdfs dfs -put /tmp/pai_yarncontainer_$CONTAINER_ID.log \
    {{{ hdfsUri }}}/Container/{{{ jobData.userName }}}/{{{ jobData.jobName }}}/log/
  kill 0
}

set -x
trap exit_handler EXIT


docker_name="$FRAMEWORK_NAME-$CONTAINER_ID"
export PAI_DEFAULT_FS_URI={{{ hdfsUri }}}

mkdir -p "/tmp/pai-root/alive/$APP_ID"
while /bin/true; do
  touch "/tmp/pai-root/alive/$APP_ID/yarn_$CONTAINER_ID"
  sleep 20
  [ -f "/tmp/pai-root/alive/$APP_ID/docker_$CONTAINER_ID" ] && [ ! "$(docker ps | grep $docker_name)" ] && break
done &

gpu_id=''
nvidia_devices=''
{{# taskData.gpuNumber }}
nvidia_devices+='--device=/dev/nvidiactl --device=/dev/nvidia-uvm'
gpu_bitmap=$(perl -e 'printf "%b",'$CONTAINER_GPUS)
for (( i=0,j=$((${#gpu_bitmap}-1)); i<${#gpu_bitmap}; i++,j-- )); do
  if [ ${gpu_bitmap:$i:1} -gt 0 ]; then
    gpu_id+="$j,"
    nvidia_devices+=" --device=/dev/nvidia$j"
  fi
done
gpu_id=$(echo $gpu_id | sed "s/,$//g")
{{/ taskData.gpuNumber }}
printf "%s %s\n%s\n\n" "[INFO]" "GPU_ID" "$gpu_id"
printf "%s %s\n%s\n\n" "[INFO]" "NVIDIA_DEVICES" "$nvidia_devices"


{{# jobData.authFile }}
IFS=$'\r\n' GLOBIGNORE='*' \
  eval 'cred=($(hdfs dfs -cat {{{ jobData.authFile }}}))' \
  || { echo 'Read authFile failed' ; exit 1; }
docker login --username ${cred[1]} --password ${cred[2]} ${cred[0]} \
  || { echo 'Authorized failed' ; exit 1; }
{{/ jobData.authFile }}


# Get container host list from framework launcher webservice
function get_host_list()
{
  delay_time=20
  info_source="webhdfs"
  while true; do
    if [[ "$info_source" = "webhdfs" ]]; then
      taskrole_statuses=$(curl -i -L -H "Accept: application/json" {{{ frameworkInfoWebhdfsUri }}} | jq -r ".aggregatedFrameworkStatus.aggregatedTaskRoleStatuses")
    else
      taskrole_statuses=$(curl -sS -X GET -H "Accept: application/json" {{{ aggregatedStatusUri }}} | jq -r ".aggregatedTaskRoleStatuses")
    fi
    jq -re ".[].taskStatuses.taskStatusArray[].containerIp" <<< $(echo $taskrole_statuses) > /dev/null
    if [ $? -eq 0 ]; then
      empty_line=$(jq -r ".[].taskStatuses.taskStatusArray[].containerIp" <<< $(echo $taskrole_statuses) | grep -c "^$")
      if [ $empty_line -eq 0 ]; then
        break
      fi
    fi
    sleep ${delay_time}s
    if [[ $delay_time -ge 300 ]]; then
      if [[ "$info_source" = "webhdfs" ]]; then
        delay_time=60
        info_source="restapi"
      else
        exit 1
      fi
    else
      delay_time=$(( "$info_source" = "webhdfs" ? delay_time + 20 : delay_time + 60 ))
    fi
  done
  for taskrole in $(echo $taskrole_statuses |  jq -r ".|keys[]"); do
    host_list=''
    while read container_ip && read container_ports; do
      host_list+=${container_ip}:$(echo $container_ports | grep -o "http:[^,;]*" | cut -f 2 -d":"),
    done < <(echo $taskrole_statuses | jq -r ".${taskrole}.taskStatuses.taskStatusArray[] | .containerIp, .containerPorts")
    host_list=$(echo $host_list | sed "s/,$//g")
    echo PAI_TASK_ROLE_${taskrole}_HOST_LIST=$host_list >> $1
  done
}


# Prepare env file
ENV_LIST=env.list

cat <<ENV >> $ENV_LIST
APP_ID=$APP_ID
FRAMEWORK_NAME=$FRAMEWORK_NAME
HADOOP_USER_NAME=$HADOOP_USER_NAME
PAI_TASK_INDEX=$TASK_INDEX
PAI_CONTAINER_HOST_IP=$CONTAINER_IP
PAI_CONTAINER_HOST_PORT_LIST=$CONTAINER_PORTS
PAI_CONTAINER_ID=$CONTAINER_ID
PAI_DEFAULT_FS_URI={{{ hdfsUri }}}
PAI_JOB_NAME={{{ jobData.jobName }}}
PAI_USER_NAME={{{ jobData.userName }}}
PAI_DATA_DIR={{{ jobData.dataDir }}}
PAI_OUTPUT_DIR={{{ jobData.outputDir }}}
PAI_CODE_DIR={{{ jobData.codeDir }}}
PAI_CURRENT_TASK_ROLE_NAME={{{ taskData.name }}}
PAI_CURRENT_TASK_ROLE_TASK_COUNT={{{ taskData.taskNumber }}}
PAI_CURRENT_TASK_ROLE_CPU_COUNT={{{ taskData.cpuNumber }}}
PAI_CURRENT_TASK_ROLE_MEM_MB={{{ taskData.memoryMB }}}
PAI_CURRENT_TASK_ROLE_GPU_COUNT={{{ taskData.gpuNumber }}}
PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX=$TASK_INDEX
PAI_JOB_TASK_COUNT={{{ tasksNumber }}}
PAI_JOB_TASK_ROLE_COUNT={{{ taskRolesNumber }}}
PAI_JOB_TASK_ROLE_LIST={{{ taskRoleList }}}
PAI_KILL_ALL_ON_COMPLETED_TASK_NUM={{{ jobData.killAllOnCompletedTaskNumber }}}
ENV

port_list=(${CONTAINER_PORTS//;/ })
for ports in "${port_list[@]}"; do
  port_label="$(cut -f 1 -d":" <<< $ports)"
  export PAI_CONTAINER_HOST_${port_label}_PORT_LIST="$(cut -f 2 -d":" <<< $ports)"
  echo PAI_CONTAINER_HOST_${port_label}_PORT_LIST="$(cut -f 2 -d":" <<< $ports)" >> $ENV_LIST
done

echo PAI_CONTAINER_HOST_PORT="$(cut -f 1 -d"," <<< $PAI_CONTAINER_HOST_http_PORT_LIST)" >> $ENV_LIST
echo PAI_CONTAINER_SSH_PORT="$(cut -f 1 -d"," <<< $PAI_CONTAINER_HOST_ssh_PORT_LIST)" >> $ENV_LIST

get_host_list $ENV_LIST

# Backward compatibility
cat <<ENV >> $ENV_LIST
# Backward compatibility
PAI_USERNAME={{{ jobData.userName }}}
PAI_TASK_ROLE_NAME={{{ taskData.name }}}
PAI_TASK_ROLE_NUM={{{ taskData.taskNumber }}}
PAI_TASK_CPU_NUM={{{ taskData.cpuNumber }}}
PAI_TASK_MEM_MB={{{ taskData.memoryMB }}}
PAI_TASK_GPU_NUM={{{ taskData.gpuNumber }}}
PAI_TASK_ROLE_INDEX=$TASK_INDEX
PAI_TASKS_NUM={{{ tasksNumber }}}
PAI_TASK_ROLES_NUM={{{ taskRolesNumber }}}
PAI_TASK_ROLE_LIST={{{ taskRoleList }}}
PAI_CURRENT_CONTAINER_IP=$CONTAINER_IP
ENV

echo PAI_CURRENT_CONTAINER_PORT="$(cut -f 1 -d"," <<< $PAI_CONTAINER_HOST_http_PORT_LIST)" >> $ENV_LIST


# Pull docker image and run
docker pull {{{ jobData.image }}} \
  || { echo 'Can not pull Docker image' ; exit 1; }
docker run --name $docker_name \
  --rm \
  --tty \
  --privileged=false \
  --cap-add=SYS_ADMIN \
  --network=host \
  --cpus={{{ taskData.cpuNumber }}} \
  --memory={{{ taskData.memoryMB }}}m \
  --oom-kill-disable \
  $nvidia_devices \
  --device=/dev/fuse \
  --security-opt apparmor:unconfined \
  --volume /var/drivers/nvidia/current:/usr/local/nvidia:ro \
  --volume /tmp/pai-root/alive/$APP_ID:/alive \
  --label GPU_ID=$gpu_id \
  --label PAI_HOSTNAME="$(hostname)" \
  --label PAI_JOB_NAME={{{ jobData.jobName }}} \
  --label PAI_JOB_VC_NAME={{{ jobData.virtualCluster }}} \
  --label PAI_USER_NAME={{{ jobData.userName }}} \
  --label PAI_CURRENT_TASK_ROLE_NAME={{{ taskData.name }}} \
  --env-file $ENV_LIST \
  --entrypoint '/bin/bash' {{{ jobData.image }}} \
  '-c' 'hdfs dfs -get {{{ hdfsUri }}}/Container/$HADOOP_USER_NAME/$FRAMEWORK_NAME/DockerContainerScripts/{{{ idx }}}.sh bootstrap.sh && /bin/bash bootstrap.sh' \
  || exit 1
